#!/usr/bin/env python3
"""
Maximum-Accuracy OCR â†’ Searchable PDF
======================================
Extracts text from scanned/image PDFs using EasyOCR with aggressive
preprocessing for maximum accuracy. Overlays invisible text layer
so the PDF becomes searchable (Ctrl+F works).

Hardware targets: i5-12th Gen, 24GB RAM, RTX 3050 (4GB VRAM)

Usage:
    python3 main2.py <input_dir> <output_dir>
    python3 main2.py <input_dir> <output_dir> --lang en --dpi 400 --workers 4

Example:
    python3 main2.py ./pdf/ ./output/
    python3 main2.py /media/pope/projecteo/OfficeLens/new/ /media/pope/projecteo/github_proj/sam_tool/out
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Imports
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import sys
import time
import argparse
import logging
import gc
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

import fitz          # PyMuPDF â€“ PDF reading/writing
import numpy as np
import cv2           # OpenCV â€“ image preprocessing
from PIL import Image, ImageEnhance, ImageFilter

import easyocr
from spellchecker import SpellChecker

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Logging
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s â”‚ %(levelname)-7s â”‚ %(message)s",
    datefmt="%H:%M:%S",
)
log = logging.getLogger("ocr")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  1.  ARGUMENT PARSING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def parse_args():
    p = argparse.ArgumentParser(
        description="Max-accuracy OCR: scanned PDF â†’ searchable PDF",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    p.add_argument("input_dir",  help="Folder with source PDFs (searched recursively)")
    p.add_argument("output_dir", help="Folder to write searchable PDFs (structure preserved)")
    p.add_argument("--lang",    default="en",  help="OCR language (default: en)")
    p.add_argument("--dpi",     type=int, default=400, help="Render DPI â€“ higher = more accurate but slower (default: 400)")
    p.add_argument("--workers", type=int, default=4,   help="Threads for image preprocessing (default: 4)")
    return p.parse_args()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  2.  IMAGE PREPROCESSING  (maximize OCR accuracy)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def preprocess_for_ocr(img_np: np.ndarray) -> np.ndarray:
    """
    Apply a pipeline of image enhancements to maximise OCR accuracy.
    Input:  RGB uint8 numpy array
    Output: RGB uint8 numpy array (enhanced)

    Pipeline:
      1. Convert to grayscale â†’ denoise â†’ sharpen â†’ adaptive threshold
      2. Convert back to RGB (EasyOCR expects 3-channel)
    """
    # --- Step 1: Grayscale ---
    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)

    # --- Step 2: Denoise (Non-local means â€“ slow but preserves edges) ---
    # h=10 : filter strength.  Larger h removes more noise but removes detail too.
    # templateWindowSize=7, searchWindowSize=21
    denoised = cv2.fastNlMeansDenoising(gray, None, h=8, templateWindowSize=7, searchWindowSize=21)

    # --- Step 3: CLAHE â€“ adaptive contrast enhancement ---
    # Improves readability of faded handwriting / low-contrast scans
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
    contrast = clahe.apply(denoised)

    # --- Step 4: Sharpen with unsharp mask ---
    blurred = cv2.GaussianBlur(contrast, (0, 0), sigmaX=2)
    sharpened = cv2.addWeighted(contrast, 1.5, blurred, -0.5, 0)

    # --- Step 5: Adaptive threshold (binarise) for cleaner text ---
    # Use a large block size for handwritten / uneven lighting
    binary = cv2.adaptiveThreshold(
        sharpened, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        blockSize=31,
        C=10,
    )

    # --- Step 6: Morphological close â€“ fill tiny gaps in strokes ---
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

    # --- Convert back to 3-channel RGB (EasyOCR requirement) ---
    rgb_out = cv2.cvtColor(closed, cv2.COLOR_GRAY2RGB)
    return rgb_out


def preprocess_light(img_np: np.ndarray) -> np.ndarray:
    """
    Lighter preprocessing â€“ just contrast + sharpen, no binarisation.
    Used as a second pass to catch text that binarisation might lose.
    """
    pil = Image.fromarray(img_np)
    pil = ImageEnhance.Contrast(pil).enhance(1.6)
    pil = ImageEnhance.Sharpness(pil).enhance(2.0)
    return np.array(pil)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  3.  OCR ENGINE INITIALISATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def init_ocr(lang: str = "en") -> easyocr.Reader:
    """Create an EasyOCR Reader, using GPU if available."""
    log.info("ğŸš€ Initialising EasyOCR â€¦")

    lang_map = {
        "en": ["en"], "ch": ["ch_sim", "en"], "ja": ["ja", "en"],
        "ko": ["ko", "en"], "fr": ["fr", "en"], "de": ["de", "en"],
        "es": ["es", "en"], "ar": ["ar", "en"], "hi": ["hi", "en"],
    }
    lang_list = lang_map.get(lang, [lang])

    use_gpu = False
    try:
        import torch
        if torch.cuda.is_available():
            use_gpu = True
            gpu_name = torch.cuda.get_device_name(0)
            gpu_mem  = torch.cuda.get_device_properties(0).total_mem / 1024**3
            log.info(f"   GPU detected: {gpu_name} ({gpu_mem:.1f} GB)")
    except Exception:
        pass

    reader = easyocr.Reader(
        lang_list,
        gpu=use_gpu,
        model_storage_directory=None,   # default cache
        download_enabled=True,
    )
    log.info(f"âœ… EasyOCR ready  â”‚ langs={lang_list}  GPU={use_gpu}")
    return reader


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  4.  SPELL CHECKER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def init_spell() -> SpellChecker:
    log.info("ğŸ“– Initialising spell checker â€¦")
    sp = SpellChecker()
    log.info("âœ… Spell checker ready")
    return sp


def fix_spelling(text: str, spell: SpellChecker) -> str:
    """
    Correct misspellings but NEVER touch:
      â€¢ words shorter than 4 chars  (likely abbreviations / math)
      â€¢ words containing digits      (formulas, codes, IDs)
      â€¢ words that are ALL CAPS       (acronyms like HTTP, API)
      â€¢ words with special chars      (file paths, URLs)
    """
    if not text:
        return text
    tokens = text.split()
    out = []
    for w in tokens:
        if (len(w) < 4
            or any(c.isdigit() for c in w)
            or w.isupper()
            or not w.isalpha()):
            out.append(w)
        elif spell.unknown([w.lower()]):
            fix = spell.correction(w.lower())
            out.append(fix if fix else w)
        else:
            out.append(w)
    return " ".join(out)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  5.  MULTI-PASS OCR ON A SINGLE PAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def ocr_page_multipass(reader: easyocr.Reader, img_np: np.ndarray):
    """
    Run OCR with TWO preprocessing passes and merge results.
    This catches text that one preprocessing mode might miss.

    Returns list of (bbox, text, confidence) â€“ deduplicated.
    """
    # --- Pass 1: Heavy preprocessing (binarised) ---
    img_heavy = preprocess_for_ocr(img_np)
    results_heavy = reader.readtext(
        img_heavy,
        detail=1,
        paragraph=False,
        min_size=10,
        text_threshold=0.5,
        low_text=0.3,
        link_threshold=0.3,
        width_ths=0.7,
        decoder="beamsearch",     # slower but more accurate than greedy
        beamWidth=10,
    )

    # --- Pass 2: Light preprocessing (contrast + sharpen only) ---
    img_light = preprocess_light(img_np)
    results_light = reader.readtext(
        img_light,
        detail=1,
        paragraph=False,
        min_size=10,
        text_threshold=0.5,
        low_text=0.3,
        link_threshold=0.3,
        width_ths=0.7,
        decoder="beamsearch",
        beamWidth=10,
    )

    # --- Merge: keep the higher-confidence result for overlapping boxes ---
    merged = {}  # key = rounded (x_center, y_center)
    for results in [results_heavy, results_light]:
        for (box, text, conf) in results:
            if not text or not text.strip():
                continue
            cx = int(np.mean([p[0] for p in box]) / 20) * 20  # quantise to 20px
            cy = int(np.mean([p[1] for p in box]) / 20) * 20
            key = (cx, cy)
            if key not in merged or conf > merged[key][2]:
                merged[key] = (box, text, conf)

    return list(merged.values())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  6.  PROCESS ONE PDF
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def process_pdf(
    pdf_path: Path,
    output_path: Path,
    reader: easyocr.Reader,
    spell: SpellChecker,
    dpi: int = 400,
):
    """
    Open a PDF, OCR every page at high DPI with multi-pass preprocessing,
    overlay invisible text, and save the searchable result.
    """
    t0 = time.time()
    try:
        doc = fitz.open(str(pdf_path))
    except Exception as e:
        log.error(f"âŒ Cannot open {pdf_path.name}: {e}")
        return

    n_pages = len(doc)
    log.info(f"ğŸ“„ {pdf_path.name}  â”‚  {n_pages} page(s)  â”‚  DPI={dpi}")
    modified = False

    for page_idx in range(n_pages):
        page = doc[page_idx]
        tp = time.time()

        # â”€â”€ Render page to image at high DPI â”€â”€
        zoom = dpi / 72.0      # fitz default is 72 DPI
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat, alpha=False)
        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(
            pix.height, pix.width, 3
        )

        # â”€â”€ Multi-pass OCR â”€â”€
        try:
            results = ocr_page_multipass(reader, img)
        except Exception as e:
            log.warning(f"   âš  OCR error p{page_idx+1}: {e}")
            results = []

        # Free heavy memory immediately
        del img, pix
        gc.collect()

        if not results:
            log.debug(f"   p{page_idx+1}: no text")
            continue

        # â”€â”€ Overlay invisible text â”€â”€
        n_inserted = 0
        for (box, raw_text, confidence) in results:
            text = fix_spelling(raw_text, spell)

            # Map image coords â†’ PDF coords  (divide by zoom)
            x_min = min(p[0] for p in box) / zoom
            y_min = min(p[1] for p in box) / zoom
            y_max = max(p[1] for p in box) / zoom
            box_h = y_max - y_min

            try:
                page.insert_text(
                    fitz.Point(x_min, y_max),
                    text,
                    fontsize=max(4, min(box_h, 20)),
                    render_mode=3,       # invisible
                )
                n_inserted += 1
                modified = True
            except Exception:
                pass

        elapsed_p = time.time() - tp
        log.info(
            f"   p{page_idx+1}/{n_pages}  â”‚  {n_inserted} text regions"
            f"  â”‚  {elapsed_p:.1f}s"
        )

    # â”€â”€ Save â”€â”€
    output_path.parent.mkdir(parents=True, exist_ok=True)
    if modified:
        doc.save(str(output_path), garbage=4, deflate=True)
        log.info(
            f"âœ… {pdf_path.name}  â”‚  {time.time()-t0:.1f}s"
            f"  â”‚  â†’ {output_path}"
        )
    else:
        doc.save(str(output_path))
        log.warning(f"âš ï¸  {pdf_path.name}: no text found (copied as-is)")

    doc.close()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  7.  MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main():
    args = parse_args()
    src  = Path(args.input_dir)
    dst  = Path(args.output_dir)

    if not src.exists():
        log.error(f"âŒ Input not found: {src}")
        sys.exit(1)

    dst.mkdir(parents=True, exist_ok=True)

    # â”€â”€ Init engines â”€â”€
    reader = init_ocr(args.lang)
    spell  = init_spell()

    # â”€â”€ Discover PDFs â”€â”€
    pdfs = sorted(src.rglob("*.pdf"))
    if not pdfs:
        log.warning("No PDFs found.")
        return

    log.info(f"ğŸ“š Found {len(pdfs)} PDF(s).  DPI={args.dpi}  Workers={args.workers}")
    log.info("=" * 60)

    t_all = time.time()
    for i, pdf in enumerate(pdfs, 1):
        rel = pdf.relative_to(src)
        out = dst / rel
        log.info(f"[{i}/{len(pdfs)}] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        process_pdf(pdf, out, reader, spell, dpi=args.dpi)

    log.info("=" * 60)
    log.info(f"ğŸ Done!  {len(pdfs)} PDFs in {time.time()-t_all:.1f}s")


if __name__ == "__main__":
    main()